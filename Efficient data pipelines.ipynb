{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T15:14:43.507848Z",
     "start_time": "2019-09-19T15:14:31.398489Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets\n",
    "Tensorflow provides various methods to create Datasets from numpy arrays, text files, CSV files, tensors, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T15:14:53.187598Z",
     "start_time": "2019-09-19T15:14:53.167581Z"
    }
   },
   "outputs": [],
   "source": [
    "# Source data - numpy array\n",
    "data = np.arange(10)\n",
    "\n",
    "# Create a dataset from numpy array\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T15:16:38.472164Z",
     "start_time": "2019-09-19T15:16:38.298131Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'arange'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7d65dcc77391>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Source data - tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'arange'"
     ]
    }
   ],
   "source": [
    "# Source data - tensor\n",
    "data = tf.arange(10) # Tensorflow v 2.0\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensors(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T15:19:00.525606Z",
     "start_time": "2019-09-19T15:19:00.497633Z"
    }
   },
   "outputs": [],
   "source": [
    "# Source data - generators\n",
    "\n",
    "def generator():\n",
    "    for i in range(10):\n",
    "        yield 2*i\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, (tf.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T15:25:40.343019Z",
     "start_time": "2019-09-19T15:25:40.280985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 11 12 13 14 15 16 17 18 19]\n",
      "[20 21 22 23 24 25 26 27 28 29]\n",
      "[30 31 32 33 34 35 36 37 38 39]\n"
     ]
    }
   ],
   "source": [
    "# Batches\n",
    "\n",
    "data = np.arange(10, 40)\n",
    "\n",
    "# Create batches of 10\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data).batch(10)\n",
    "\n",
    "# Create iterator to consume the data\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_ele = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    try: \n",
    "        while True:\n",
    "            val = sess.run(next_ele)\n",
    "            print(val)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T15:35:54.231055Z",
     "start_time": "2019-09-19T15:35:54.159047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([10, 11]), array([11, 12]))\n",
      "(array([12, 13]), array([13, 14]))\n",
      "(array([14, 15]), array([15, 16]))\n",
      "(array([16, 17]), array([17, 18]))\n",
      "(array([18, 19]), array([19, 20]))\n"
     ]
    }
   ],
   "source": [
    "# Zip \n",
    "\n",
    "datax = np.arange(10, 20)\n",
    "datay = np.arange(11, 21)\n",
    "\n",
    "datasetx = tf.data.Dataset.from_tensor_slices(datax)\n",
    "datasety = tf.data.Dataset.from_tensor_slices(datay)\n",
    "\n",
    "dcombined = tf.data.Dataset.zip((datasetx, datasety)).batch(2)\n",
    "iterator = dcombined.make_one_shot_iterator()\n",
    "next_ele = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            val = sess.run(next_ele)\n",
    "            print(val)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T15:38:56.035475Z",
     "start_time": "2019-09-19T15:38:55.975459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Repeat\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
    "dataset = dataset.repeat(count=2)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_ele = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            val = sess.run(next_ele)\n",
    "            print(val)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T15:43:58.771124Z",
     "start_time": "2019-09-19T15:43:58.712126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# Map: Transfor data before feeding into the model\n",
    "\n",
    "def map_fnc(x):\n",
    "    return x*2;\n",
    "\n",
    "data = np.arange(10)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "dataset = dataset.map(map_fnc)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_ele = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            val = sess.run(next_ele)\n",
    "            print(val)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Iterators\n",
    "\n",
    "Tensorflow provides Iterators to consume the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T15:47:55.599453Z",
     "start_time": "2019-09-19T15:47:55.558419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# one-shot iterator\n",
    "\n",
    "data = np.arange(10, 15)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "\n",
    "# create iterator \n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    val = sess.run(next_element)\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T15:55:58.659554Z",
     "start_time": "2019-09-19T15:55:58.105289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# initializable iterator\n",
    "\n",
    "# define two placeholders to accept min and max value\n",
    "min_val = tf.placeholder(tf.int32, shape=[])\n",
    "max_val = tf.placeholder(tf.int32, shape=[])\n",
    "\n",
    "data = tf.range(min_val, max_val)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_ele = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize an iterator with range of values from 10 to 15\n",
    "    sess.run(iterator.initializer, feed_dict={min_val:10, max_val:15})\n",
    "    try:\n",
    "        while True:\n",
    "            val = sess.run(next_ele)\n",
    "            print(val)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    \n",
    "    # initialize an iterator with range of values from 1 to 10\n",
    "    sess.run(iterator.initializer, feed_dict={min_val:1, max_val:10})\n",
    "    try:\n",
    "        while True:\n",
    "            val = sess.run(next_ele)\n",
    "            print(val)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T16:10:01.589209Z",
     "start_time": "2019-09-19T16:10:01.494691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Reinitializable iterator \n",
    "\n",
    "def map_fnc(ele):\n",
    "    return ele*2\n",
    "\n",
    "min_val = tf.placeholder(tf.int32, shape=[])\n",
    "max_val = tf.placeholder(tf.int32, shape=[])\n",
    "data = tf.range(min_val, max_val)\n",
    "\n",
    "# Define separate datasets fro training and validation\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(data).map(map_fnc)\n",
    "\n",
    "# Create iterator \n",
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "\n",
    "train_initializer = iterator.make_initializer(train_dataset)\n",
    "val_initializer = iterator.make_initializer(val_dataset)\n",
    "\n",
    "next_ele = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # initialize an iterator with range of values from 10 to 15\n",
    "    sess.run(train_initializer, feed_dict={min_val:10, max_val:15})\n",
    "    try:\n",
    "        while True:\n",
    "            val = sess.run(next_ele)\n",
    "            print(val)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    \n",
    "    # initialize an iterator with range of values from 1 to 10\n",
    "    sess.run(train_initializer, feed_dict={min_val:1, max_val:10})\n",
    "    try:\n",
    "        while True:\n",
    "            val = sess.run(next_ele)\n",
    "            print(val)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T16:20:58.190744Z",
     "start_time": "2019-09-19T16:20:58.042730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# Feedable iterator: Can be used to switch between Iterators for different Datasets.\n",
    "\n",
    "def map_fnc(ele):\n",
    "    return ele*2\n",
    "\n",
    "min_val = tf.placeholder(tf.int32, shape=[])\n",
    "max_val = tf.placeholder(tf.int32, shape=[])\n",
    "data = tf.range(min_val, max_val)\n",
    "\n",
    "# Define separate datasets fro training and validation\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(data).map(map_fnc)\n",
    "\n",
    "train_val_iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "train_initializer = train_val_iterator.make_initializer(train_dataset)\n",
    "val_initializer = train_val_iterator.make_initializer(val_dataset)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(tf.range(10, 15))\n",
    "test_iterator = test_dataset.make_one_shot_iterator()\n",
    "\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle, train_dataset.output_types, train_dataset.output_shapes)\n",
    "next_ele = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    train_val_handle = sess.run(train_val_iterator.string_handle())\n",
    "    test_handle = sess.run(test_iterator.string_handle())\n",
    "    \n",
    "    # training\n",
    "    sess.run(train_initializer, feed_dict={min_val:10, max_val:15})\n",
    "    try:\n",
    "        while True:\n",
    "            val = sess.run(next_ele, feed_dict={handle:train_val_handle})\n",
    "            print(val)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    \n",
    "    # validation\n",
    "    sess.run(train_initializer, feed_dict={min_val:1, max_val:10})\n",
    "    try:\n",
    "        while True:\n",
    "            val = sess.run(next_ele, feed_dict={handle:train_val_handle})\n",
    "            print(val)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    \n",
    "    # testing\n",
    "    try:\n",
    "        while True:\n",
    "            val = sess.run(next_ele, feed_dict={handle:test_handle})\n",
    "            print(val)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-5 Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T16:43:53.723271Z",
     "start_time": "2019-09-19T16:43:51.607248Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-5a559bbb352e>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\antonio.martinez2\\AppData\\Local\\Continuum\\anaconda3\\envs\\Python35Tensorflow112\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\antonio.martinez2\\AppData\\Local\\Continuum\\anaconda3\\envs\\Python35Tensorflow112\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\antonio.martinez2\\AppData\\Local\\Continuum\\anaconda3\\envs\\Python35Tensorflow112\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\antonio.martinez2\\AppData\\Local\\Continuum\\anaconda3\\envs\\Python35Tensorflow112\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\antonio.martinez2\\AppData\\Local\\Continuum\\anaconda3\\envs\\Python35Tensorflow112\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False, one_hot=True)\n",
    "\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels\n",
    "\n",
    "X_train = np.pad(X_train, ((0,0), (2,2), (2,2), (0,0)), 'constant')\n",
    "X_val = np.pad(X_val, ((0,0), (2,2), (2,2), (0,0)), 'constant')\n",
    "X_test = np.pad(X_test, ((0,0), (2,2), (2,2), (0,0)), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T16:48:33.981584Z",
     "start_time": "2019-09-19T16:48:33.969587Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward_pass(X):\n",
    "    W1 = tf.get_variable(\"W1\", [5,5,1,6], initializer = tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    # for conv layer2\n",
    "    W2 = tf.get_variable(\"W2\", [5,5,6,16], initializer = tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides = [1,1,1,1], padding='VALID')\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,2,2,1], strides = [1,2,2,1], padding='VALID')\n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides = [1,1,1,1], padding='VALID')\n",
    "    A2= tf.nn.relu(Z2)\n",
    "    P2= tf.nn.max_pool(A2, ksize = [1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "   \n",
    "    Z3 = tf.contrib.layers.fully_connected(P2, 120)\n",
    "    Z4 = tf.contrib.layers.fully_connected(Z3, 84)\n",
    "    Z5 = tf.contrib.layers.fully_connected(Z4,10, activation_fn= None)\n",
    "    \n",
    "    return Z5\n",
    "\n",
    "def model(X,Y):\n",
    "    \n",
    "    logits = forward_pass(X)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.0009)\n",
    "    learner = optimizer.minimize(cost)\n",
    "    correct_predictions = tf.equal(tf.argmax(logits,1),   tf.argmax(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "    \n",
    "    return (learner, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T16:48:48.219502Z",
     "start_time": "2019-09-19T16:48:37.162809Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-9100c00092ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mtemp_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearner\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mtotal_accuracy\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtemp_accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\Python35Tensorflow112\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\Python35Tensorflow112\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1073\u001b[0m     \u001b[1;31m# Check session.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1075\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Attempted to use a closed Session.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1076\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "# one-shot iterator\n",
    "\n",
    "epochs = 10 \n",
    "batch_size = 64 \n",
    "iterations = len(y_train) * epochs\n",
    "\n",
    "tf.reset_default_graph()\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "\n",
    "# need to repeat the dataset for epoch number of times, as all the data needs\n",
    "# to be fed to the dataset at once\n",
    "\n",
    "dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "X_batch , Y_batch = iterator.get_next()\n",
    "(learner, accuracy) = model(X_batch, Y_batch)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "    total_accuracy = 0\n",
    "try:\n",
    "    while True:\n",
    "        temp_accuracy, _ = sess.run([accuracy, learner])\n",
    "        total_accuracy += temp_accuracy\n",
    "except tf.errors.OutOfRangeError:\n",
    "    pass\n",
    "  \n",
    "print('Avg training accuracy is {}'.format((total_accuracy * batch_size) / iterations ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T16:51:18.800092Z",
     "start_time": "2019-09-19T16:50:32.054178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "---------------------------\n",
      "Training accuracy is 0.9212545454545454\n",
      "Validation accuracy is 0.9724\n",
      "Epoch 2\n",
      "---------------------------\n",
      "Training accuracy is 0.9742727272727273\n",
      "Validation accuracy is 0.9856\n",
      "Epoch 3\n",
      "---------------------------\n",
      "Training accuracy is 0.9822909090909091\n",
      "Validation accuracy is 0.9926\n",
      "Epoch 4\n",
      "---------------------------\n",
      "Training accuracy is 0.9867636363636364\n",
      "Validation accuracy is 0.9952\n",
      "Epoch 5\n",
      "---------------------------\n",
      "Training accuracy is 0.9900363636363636\n",
      "Validation accuracy is 0.995\n",
      "Epoch 6\n",
      "---------------------------\n",
      "Training accuracy is 0.9922181818181818\n",
      "Validation accuracy is 0.995\n",
      "Epoch 7\n",
      "---------------------------\n",
      "Training accuracy is 0.9938545454545454\n",
      "Validation accuracy is 0.9956\n",
      "Epoch 8\n",
      "---------------------------\n",
      "Training accuracy is 0.9940727272727272\n",
      "Validation accuracy is 0.9974\n",
      "Epoch 9\n",
      "---------------------------\n",
      "Training accuracy is 0.9952727272727273\n",
      "Validation accuracy is 0.9984\n",
      "Epoch 10\n",
      "---------------------------\n",
      "Training accuracy is 0.9956\n",
      "Validation accuracy is 0.9984\n"
     ]
    }
   ],
   "source": [
    "# initializable iterator\n",
    "\n",
    "epochs = 10 \n",
    "batch_size = 64\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X_data = tf.placeholder(tf.float32, [None, 32,32,1])\n",
    "Y_data = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_data, Y_data))\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "X_batch , Y_batch = iterator.get_next()\n",
    "(learner, accuracy) = model(X_batch, Y_batch)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # train the model\n",
    "        sess.run(iterator.initializer, feed_dict={X_data:X_train, Y_data:y_train})\n",
    "        total_train_accuracy = 0\n",
    "        no_train_examples = len(y_train)\n",
    "        try:\n",
    "            while True:\n",
    "                temp_train_accuracy, _ = sess.run([accuracy, learner])\n",
    "                total_train_accuracy += temp_train_accuracy*batch_size\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "\n",
    "        # validate the model\n",
    "        sess.run(iterator.initializer, feed_dict={X_data:X_val, Y_data:y_val})\n",
    "        total_val_accuracy = 0\n",
    "        no_val_examples = len(y_val)\n",
    "        try:\n",
    "            while True:\n",
    "                temp_val_accuracy = sess.run(accuracy)\n",
    "                total_val_accuracy += temp_val_accuracy*batch_size\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "\n",
    "        print('Epoch {}'.format(str(epoch+1)))\n",
    "        print(\"---------------------------\")\n",
    "        print('Training accuracy is {}'.format(total_train_accuracy/no_train_examples))\n",
    "        print('Validation accuracy is {}'.format(total_val_accuracy/no_val_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T16:53:19.660057Z",
     "start_time": "2019-09-19T16:52:34.516756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "---------------------------\n",
      "Training accuracy is 0.9188363636363637\n",
      "Validation accuracy is 0.9666\n",
      "Epoch 2\n",
      "---------------------------\n",
      "Training accuracy is 0.974733333310214\n",
      "Validation accuracy is 0.9856\n",
      "Epoch 3\n",
      "---------------------------\n",
      "Training accuracy is 0.9822909090909091\n",
      "Validation accuracy is 0.9952\n",
      "Epoch 4\n",
      "---------------------------\n",
      "Training accuracy is 0.9864\n",
      "Validation accuracy is 0.994\n",
      "Epoch 5\n",
      "---------------------------\n",
      "Training accuracy is 0.9892727272727273\n",
      "Validation accuracy is 0.9976\n",
      "Epoch 6\n",
      "---------------------------\n",
      "Training accuracy is 0.992\n",
      "Validation accuracy is 0.9918\n",
      "Epoch 7\n",
      "---------------------------\n",
      "Training accuracy is 0.9927636363636364\n",
      "Validation accuracy is 0.9982\n",
      "Epoch 8\n",
      "---------------------------\n",
      "Training accuracy is 0.993890909090909\n",
      "Validation accuracy is 0.9972\n",
      "Epoch 9\n",
      "---------------------------\n",
      "Training accuracy is 0.9937454545454546\n",
      "Validation accuracy is 0.9968\n",
      "Epoch 10\n",
      "---------------------------\n",
      "Training accuracy is 0.9951454545454546\n",
      "Validation accuracy is 0.9992\n"
     ]
    }
   ],
   "source": [
    "# Re-initializable iterator\n",
    "def map_fnc(X, Y):\n",
    "     return X, Y\n",
    "    \n",
    "epochs = 10 \n",
    "batch_size = 64\n",
    "tf.reset_default_graph()\n",
    "X_data = tf.placeholder(tf.float32, [None, 32,32,1])\n",
    "Y_data = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_data, Y_data)).batch(batch_size).map(map_fnc)\n",
    "val_dataset =  tf.data.Dataset.from_tensor_slices((X_data, Y_data)).batch(batch_size)\n",
    "\n",
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "X_batch , Y_batch = iterator.get_next()\n",
    "(learner, accuracy) = model(X_batch, Y_batch)\n",
    "\n",
    "train_initializer = iterator.make_initializer(train_dataset)\n",
    "val_initializer =  iterator.make_initializer(val_dataset)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        # train the model\n",
    "        sess.run(train_initializer, feed_dict={X_data:X_train, Y_data:y_train})\n",
    "        total_train_accuracy = 0\n",
    "        no_train_examples = len(y_train)\n",
    "        try:\n",
    "            while True:\n",
    "                temp_train_accuracy, _ = sess.run([accuracy, learner])\n",
    "                total_train_accuracy += temp_train_accuracy*batch_size\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "\n",
    "        # validate the model\n",
    "        sess.run(val_initializer, feed_dict={X_data:X_val, Y_data:y_val})\n",
    "        total_val_accuracy = 0\n",
    "        no_val_examples = len(y_val)\n",
    "        try:\n",
    "            while True:\n",
    "                temp_val_accuracy = sess.run(accuracy)\n",
    "                total_val_accuracy += temp_val_accuracy*batch_size\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "\n",
    "        print('Epoch {}'.format(str(epoch+1)))\n",
    "        print(\"---------------------------\")\n",
    "        print('Training accuracy is {}'.format(total_train_accuracy/no_train_examples))\n",
    "        print('Validation accuracy is {}'.format(total_val_accuracy/no_val_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-19T16:58:01.659493Z",
     "start_time": "2019-09-19T16:57:06.463396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "---------------------------\n",
      "Training accuracy is 0.9195272727272727\n",
      "Validation accuracy is 0.9768\n",
      "Epoch 2\n",
      "---------------------------\n",
      "Training accuracy is 0.9747090909090909\n",
      "Validation accuracy is 0.991\n",
      "Epoch 3\n",
      "---------------------------\n",
      "Training accuracy is 0.9828181818181818\n",
      "Validation accuracy is 0.995\n",
      "Epoch 4\n",
      "---------------------------\n",
      "Training accuracy is 0.9870181818181818\n",
      "Validation accuracy is 0.9988\n",
      "Epoch 5\n",
      "---------------------------\n",
      "Training accuracy is 0.9895090909090909\n",
      "Validation accuracy is 1.0012\n",
      "Epoch 6\n",
      "---------------------------\n",
      "Training accuracy is 0.9917636363636364\n",
      "Validation accuracy is 1.0018\n",
      "Epoch 7\n",
      "---------------------------\n",
      "Training accuracy is 0.9935272727272727\n",
      "Validation accuracy is 1.0052\n",
      "Epoch 8\n",
      "---------------------------\n",
      "Training accuracy is 0.9943090909090909\n",
      "Validation accuracy is 1.0028\n",
      "Epoch 9\n",
      "---------------------------\n",
      "Training accuracy is 0.9948\n",
      "Validation accuracy is 1.0054\n",
      "Epoch 10\n",
      "---------------------------\n",
      "Training accuracy is 0.9950545454545454\n",
      "Validation accuracy is 1.0058\n",
      "Testing the model --------\n",
      "Testing accuracy is 0.9913\n"
     ]
    }
   ],
   "source": [
    "# Feedable iterator\n",
    "\n",
    "epochs = 10 \n",
    "batch_size = 64\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X_data = tf.placeholder(tf.float32, [None, 32,32,1])\n",
    "Y_data = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_data, Y_data)).batch(batch_size)\n",
    "val_dataset =  tf.data.Dataset.from_tensor_slices((X_data, Y_data)).batch(batch_size)\n",
    "test_dataset =  tf.data.Dataset.from_tensor_slices((X_test, y_test.astype(np.float32))).batch(batch_size)\n",
    "\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle, train_dataset.output_types, train_dataset.output_shapes)\n",
    "X_batch , Y_batch = iterator.get_next()\n",
    "(learner, accuracy) = model(X_batch, Y_batch)\n",
    "\n",
    "train_val_iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "train_iterator = train_val_iterator.make_initializer(train_dataset)\n",
    "val_iterator = train_val_iterator.make_initializer(val_dataset)\n",
    "test_iterator = test_dataset.make_one_shot_iterator()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_val_string_handle = sess.run(train_val_iterator.string_handle())\n",
    "    test_string_handle = sess.run(test_iterator.string_handle())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # train the model\n",
    "        sess.run(train_iterator, feed_dict={X_data:X_train, Y_data:y_train})\n",
    "        total_train_accuracy = 0\n",
    "        no_train_examples = len(y_train)\n",
    "        try:\n",
    "            while True:\n",
    "                temp_train_accuracy, _ = sess.run([accuracy, learner], feed_dict={handle:train_val_string_handle})\n",
    "                total_train_accuracy += temp_train_accuracy*batch_size\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "\n",
    "        # validate the model\n",
    "        sess.run(val_iterator, feed_dict={X_data:X_val, Y_data:y_val})\n",
    "        total_val_accuracy = 0\n",
    "        no_val_examples = len(y_val)\n",
    "        try:\n",
    "            while True:\n",
    "                temp_val_accuracy, _ = sess.run([accuracy, learner], feed_dict={handle:train_val_string_handle})\n",
    "                total_val_accuracy += temp_val_accuracy*batch_size\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "\n",
    "        print('Epoch {}'.format(str(epoch+1)))\n",
    "        print(\"---------------------------\")\n",
    "        print('Training accuracy is {}'.format(total_train_accuracy/no_train_examples))\n",
    "        print('Validation accuracy is {}'.format(total_val_accuracy/no_val_examples))\n",
    "\n",
    "\n",
    "    print(\"Testing the model --------\")\n",
    "\n",
    "    total_test_accuracy = 0\n",
    "    no_test_examples = len(y_test)\n",
    "    try:\n",
    "        while True:\n",
    "            temp_test_accuracy, _ = sess.run([accuracy, learner], feed_dict={handle:test_string_handle})\n",
    "            total_test_accuracy += temp_test_accuracy*batch_size\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "    print('Testing accuracy is {}'.format(total_test_accuracy/no_test_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Python35Tensorflow112] *",
   "language": "python",
   "name": "conda-env-Python35Tensorflow112-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
