{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T23:18:46.752323Z",
     "start_time": "2019-08-23T23:18:11.404343Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python import debug as tf_debug\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T23:19:25.375029Z",
     "start_time": "2019-08-23T23:19:25.369990Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a subfolder for each log\n",
    "subFolder = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = f\"./tfb_logs/{subFolder}/\"\n",
    "\n",
    "# only log errors (to prevent unnecessary cluttering on the console)\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T23:20:09.437751Z",
     "start_time": "2019-08-23T23:19:26.530991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# We use the TF helper function to pull down the data from MNIST site\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T23:20:10.487592Z",
     "start_time": "2019-08-23T23:20:10.453412Z"
    }
   },
   "outputs": [],
   "source": [
    "# x is the placeholder for the 28 * 28 imagen data (the input)\n",
    "# y_ is a 10 element vector, containing the predicted probability of each digit (0-9) class\n",
    "# Define the weights and balances (always keep the dimensions in mind)\n",
    "with tf.name_scope(\"variable_scope\"):\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x_placeholder\")\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 10], name=\"y_placeholder\")\n",
    "    tf.summary.image(\"image_input\", tf.reshape(x, [-1, 28, 28, 1]), 3)\n",
    "\n",
    "    with tf.name_scope(\"weights_scope\"):\n",
    "        W = tf.Variable(tf.zeros([784, 10]), name=\"weights_variable\")\n",
    "        tf.summary.histogram(\"weight_histogram\", W)\n",
    "\n",
    "    with tf.name_scope(\"bias_scope\"):\n",
    "        b = tf.Variable(tf.zeros([10]), name=\"bias_variable\")\n",
    "        tf.summary.histogram(\"bias_histogram\", b)\n",
    "   \n",
    "    # Define the activation function = the real y. Donot use softmax here, as it will be applied in\n",
    "    # --- Debugging code ---\n",
    "    assert x.get_shape().as_list() == [None, 784]\n",
    "    assert y_.get_shape().as_list() == [None, 10]\n",
    "    assert W.get_shape().as_list() == [784, 10]\n",
    "    assert b.get_shape().as_list() == [10]\n",
    "    # ----------------------\n",
    "    with tf.name_scope(\"yReal_scope\"):\n",
    "        y = tf.matmul(x, W) + b\n",
    "        tf.summary.histogram(\"yReal_histogram\", y)\n",
    "\n",
    "    assert y.get_shape().as_list() == [None, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T23:20:11.634089Z",
     "start_time": "2019-08-23T23:20:11.558978Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss is defined as cross entropy between the prediction and the real value\n",
    "with tf.name_scope(\"loss_scope\"):\n",
    "    loss = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                labels=y_, logits=y, name=\"lossFunction\"\n",
    "            ),\n",
    "            name=\"loss\"\n",
    "        )\n",
    "\n",
    "with tf.name_scope(\"training_scope\"):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss, name=\"gradDescent\")\n",
    "    tf.summary.histogram(\"loss_histogram\", loss)\n",
    "    tf.summary.scalar(\"loss_scalar\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T23:20:12.331814Z",
     "start_time": "2019-08-23T23:20:12.316780Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the accuracy of the model\n",
    "with tf.name_scope(\"accuracy_scope\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")\n",
    "    tf.summary.histogram(\"accurace_scalar\", accuracy)\n",
    "    tf.summary.scalar(\"accurace_scalar\", accuracy)\n",
    "# --- Debug --- # \n",
    "#print(\"===========================\")\n",
    "#print(f\"The bias parameter is: {sess.run(b, feed_dict={x: mnist.test.images, y_: mnist.test.labels})}\")\n",
    "#print(f\"Acuracy of the model is: {sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})*100}%\")\n",
    "\n",
    "#-------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T23:20:17.394612Z",
     "start_time": "2019-08-23T23:20:13.469508Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15 ops no flops stats due to incomplete shapes.\n",
      "15 ops no flops stats due to incomplete shapes.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'UnimplementedError' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0be75f6e3e3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_summary_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mtbWriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\Python35Tensorflow112\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py\u001b[0m in \u001b[0;36madd_summary\u001b[1;34m(self, summary, global_step)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;31m# to save space - we just store the metadata on the first value with a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;31m# specific tag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'UnimplementedError' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "# Initialize all variables\n",
    "\n",
    "# Perform the initialization which is only the initialization of all global variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Set session\n",
    "#sess = tf.Session()\n",
    "sess = tf.InteractiveSession()\n",
    "sess = tf_debug.TensorBoardDebugWrapperSession(sess, \"localhost:8080\")\n",
    "sess.run(init)\n",
    "\n",
    "# TensorBoard - Write the default graph out so we can view it's structure\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "tbWriter = tf.summary.FileWriter(logdir)\n",
    "tbWriter.add_graph(sess.graph)\n",
    "\n",
    "# Perform 1000 training steps\n",
    "# Feed the next batch and run the training\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    if i % 5 == 0:\n",
    "        summary = sess.run(merged_summary_op, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        tbWriter.add_summary(summary, i)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T23:15:56.081638Z",
     "start_time": "2019-08-23T23:15:56.038634Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"===========================\")\n",
    "print(\n",
    "    f\"Accuracy of the model is: {sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})*100}%\"\n",
    ")\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T21:24:49.842032Z",
     "start_time": "2019-08-23T21:24:49.814060Z"
    }
   },
   "outputs": [],
   "source": [
    "test_accuracy = sess.run(\n",
    "    accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}\n",
    ")\n",
    "print(\"Test Accuracy: {}%\".format(test_accuracy * 100.0))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Python35Tensorflow112] *",
   "language": "python",
   "name": "conda-env-Python35Tensorflow112-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
