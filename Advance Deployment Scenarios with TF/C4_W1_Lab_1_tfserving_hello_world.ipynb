{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "C4_W1_Lab_1_tfserving_hello_world.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA5mNKv1jOET"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B94t_egKjOEV"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXdXzdwpo45D"
      },
      "source": [
        "# Getting Started with TensorFlow Serving\n",
        "\n",
        "In this notebook you will serve your first TensorFlow model with TensorFlow Serving. We will start by building a very simple model to infer the relationship:\n",
        "\n",
        "$$\n",
        "y = 2x - 1 \n",
        "$$\n",
        "\n",
        "between a few pairs of numbers. After training our model, we will serve it with TensorFlow Serving, and then we will make inference requests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo0JfluI1Vzw"
      },
      "source": [
        "**Warning: This notebook is designed to be run in a Google Colab only**.  It installs packages on the system and requires root access.  If you want to run it in a local Jupyter notebook, please proceed with caution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5MGykVsYQXq"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcV03BQ0o45G"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzLKpmZICaWN",
        "outputId": "03aeaaee-dc0a-4bb2-a801-662be62b2d9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "â€¢ Using TensorFlow Version: 2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd-XtLMispqY"
      },
      "source": [
        "## Add TensorFlow Serving Distribution URI as a Package Source\n",
        "\n",
        "We will install TensorFlow Serving using [Aptitude](https://wiki.debian.org/Aptitude) (the default Debian package manager) since Google's Colab runs in a Debian environment. \n",
        "\n",
        "Before we can install TensorFlow Serving, we need to add the `tensorflow-model-server` package to the list of packages that Aptitude knows about. Note that we're running as root.\n",
        "\n",
        "**Note**: This notebook is running TensorFlow Serving natively, but [you can also run it in a Docker container](https://www.tensorflow.org/tfx/serving/docker), which is one of the easiest ways to get started using TensorFlow Serving. The Docker Engine is available for a variety of Linux platforms, Windows, and Mac."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbU7MZtcZboG",
        "outputId": "2b9e7e28-c8f1-47f6-a8e0-ab8f14778828",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# This is the same as you would do from your command line, but without the [arch=amd64], and no sudo\n",
        "# You would instead do:\n",
        "# echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "# curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
        "\n",
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2943  100  2943    0     0  31645      0 --:--:-- --:--:-- --:--:-- 31645\n",
            "OK\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:11 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [340 B]\n",
            "Get:12 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [347 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:15 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Ign:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [634 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:18 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [473 kB]\n",
            "Get:20 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,418 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,221 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,777 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,188 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [506 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,657 kB]\n",
            "Get:27 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [909 kB]\n",
            "Get:28 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.9 kB]\n",
            "Get:29 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [41.5 kB]\n",
            "Fetched 13.2 MB in 5s (2,681 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "89 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT6BgcLFtN8E"
      },
      "source": [
        "## Install TensorFlow Serving\n",
        "\n",
        "Now that the Aptitude packages have been updated, we can use the `apt-get` command to install the TensorFlow model server."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoHTRDi1Zf_Z",
        "outputId": "f05d9a84-3873-44df-fa4e-ebc94bd2a168",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 89 not upgraded.\n",
            "Need to get 326 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.5.1 [326 MB]\n",
            "Fetched 326 MB in 4s (73.2 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.5.1_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.5.1) ...\n",
            "Setting up tensorflow-model-server (2.5.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5u6UVdJ2K0W"
      },
      "source": [
        "## Create Dataset\n",
        "\n",
        "Now, we will create a simple dataset that expresses the relationship:\n",
        "\n",
        "$$\n",
        "y = 2x - 1 \n",
        "$$\n",
        "\n",
        "between inputs (`xs`) and outputs (`ys`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qqsNxy83Imw"
      },
      "source": [
        "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6frUt2r3NYJ"
      },
      "source": [
        "## Build and Train the Model\n",
        "\n",
        "We'll use the simplest possible model for this example. Since we are going to train our model for `500` epochs, in order to avoid clutter on the screen, we will use the argument `verbose=0` in the `fit` method. The Verbosity mode can be:\n",
        "\n",
        "* `0` : silent.\n",
        "\n",
        "* `1` : progress bar.\n",
        "\n",
        "* `2` : one line per epoch.\n",
        "\n",
        "As a side note, we should mention that since the progress bar is not particularly useful when logged to a file, `verbose=2` is recommended when not running interactively (eg, in a production environment)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9952f7iAaT9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d354ff6b-c852-4033-c55f-51d06c413235"
      },
      "source": [
        "model = tf.keras.Sequential([tf.keras.layers.Dense(units=1, input_shape=[1])])\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='mean_squared_error')\n",
        "\n",
        "history = model.fit(xs, ys, epochs=500, verbose=1)\n",
        "\n",
        "print(\"Finished training the model\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 3s 3s/step - loss: 4.4814\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.6959\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0745\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5822\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1915\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8808\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6332\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4352\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2763\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1483\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0447\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9602\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8909\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8336\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7858\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7455\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7112\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6817\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6559\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6332\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6129\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5946\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5779\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5625\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5481\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5347\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5220\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5099\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4983\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4873\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4766\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4663\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4563\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4466\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4372\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4280\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4191\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4103\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4018\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3935\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3853\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3774\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3696\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3620\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3545\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3472\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3401\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3331\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3262\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3195\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3129\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3065\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3002\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2940\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2880\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2821\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2763\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2706\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2650\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2596\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2543\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2490\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2439\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2389\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2340\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2292\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2245\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2199\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2154\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2109\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2066\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2024\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1982\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1941\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1901\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1862\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1824\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1787\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1750\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1714\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1679\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1644\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1611\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1577\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1545\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1513\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1482\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1452\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1422\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1393\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1364\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1336\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1309\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1282\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1256\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1230\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1204\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1180\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1155\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1132\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1109\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1086\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1063\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1042\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1020\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0999\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0979\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0959\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0939\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0920\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0901\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0882\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0864\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0846\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0829\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0812\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0795\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0779\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0763\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0747\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0732\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0717\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0702\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0688\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0674\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0660\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0646\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0633\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0620\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0607\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0595\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0583\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0571\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0559\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0547\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0536\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0525\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0514\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0504\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0493\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0483\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0473\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0464\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0454\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0445\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0436\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0427\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0418\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0409\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0401\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0393\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0385\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0377\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0369\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0361\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0354\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0347\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0340\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0333\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0326\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0319\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0313\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0306\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0300\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0294\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0288\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0282\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0276\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0270\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0265\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0259\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0254\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0249\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0244\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0239\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0234\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0229\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0224\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0220\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0215\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0211\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0206\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0202\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0198\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0194\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0190\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0186\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0182\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0178\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0175\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0171\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0168\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0164\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0161\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0158\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0154\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0151\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0148\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0145\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0142\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0139\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0136\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0133\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0131\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0128\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0125\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0123\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0120\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0118\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0115\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0113\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0111\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0108\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0106\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0104\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0102\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0100\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0098\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0096\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0094\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0092\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0090\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0088\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0086\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0085\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0083\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0081\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0079\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0078\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0076\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0073\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0072\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0070\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0069\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0067\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0066\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0065\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0063\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0062\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0061\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0059\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0058\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0057\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0056\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0055\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0054\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0052\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0051\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0050\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0049\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0048\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0047\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0046\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0045\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0044\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0044\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0043\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0042\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0041\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0040\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0039\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0038\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0038\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0037\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0036\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0035\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0035\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0034\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0033\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0033\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0032\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0031\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0031\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0030\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0029\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0029\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0028\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0028\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0027\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0026\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0025\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0025\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0024\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0023\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0023\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0022\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0022\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0021\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0020\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0020\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0019\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0019\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0019\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0018\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0017\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0017\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0017\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0016\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0016\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0016\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0015\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0015\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0014\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0014\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0014\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0013\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0013\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0012\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0012\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0011\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0011\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0010\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0010\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.9692e-04\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.7644e-04\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.5639e-04\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.3674e-04\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.1750e-04\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.9865e-04\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.8019e-04\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.6212e-04\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4441e-04\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.2706e-04\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.1007e-04\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.9343e-04\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.7713e-04\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.6117e-04\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4554e-04\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.3022e-04\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1522e-04\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0053e-04\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.8614e-04\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7205e-04\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.5824e-04\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4473e-04\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3148e-04\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 6.1851e-04\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0581e-04\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9336e-04\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.8117e-04\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.6924e-04\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5754e-04\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4609e-04\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3487e-04\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2389e-04\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1313e-04\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0259e-04\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.9226e-04\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8215e-04\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7225e-04\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6255e-04\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.5305e-04\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.4374e-04\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.3463e-04\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.2570e-04\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.1696e-04\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0839e-04\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0000e-04\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9178e-04\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8374e-04\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7586e-04\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6814e-04\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6057e-04\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5317e-04\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4591e-04\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3881e-04\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3185e-04\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2503e-04\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1836e-04\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1182e-04\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0541e-04\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9914e-04\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9299e-04\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8698e-04\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8108e-04\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7531e-04\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6965e-04\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6412e-04\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5869e-04\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5338e-04\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4817e-04\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4307e-04\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3808e-04\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3319e-04\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2840e-04\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2371e-04\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1912e-04\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1462e-04\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1021e-04\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0589e-04\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0166e-04\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9752e-04\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9346e-04\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8949e-04\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8560e-04\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8178e-04\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7805e-04\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7439e-04\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1.7081e-04\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6730e-04\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6387e-04\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6050e-04\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5720e-04\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5397e-04\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5081e-04\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4771e-04\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4468e-04\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4170e-04\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3880e-04\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3594e-04\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3315e-04\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3042e-04\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2774e-04\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2512e-04\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.2254e-04\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2003e-04\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1756e-04\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1515e-04\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1278e-04\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1046e-04\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0820e-04\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0597e-04\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0380e-04\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0166e-04\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.9577e-05\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.7531e-05\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.5528e-05\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.3565e-05\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.1645e-05\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9763e-05\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.7918e-05\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.6112e-05\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4344e-05\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.2611e-05\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.0915e-05\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.9252e-05\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.7625e-05\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6031e-05\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4468e-05\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2939e-05\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1441e-05\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9975e-05\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8537e-05\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.7129e-05\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5751e-05\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.4400e-05\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.3077e-05\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.1782e-05\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.0513e-05\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9270e-05\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.8053e-05\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.6860e-05\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.5692e-05\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4548e-05\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.3428e-05\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2330e-05\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.1256e-05\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.0202e-05\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9171e-05\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.8161e-05\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.7171e-05\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.6203e-05\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.5254e-05\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4324e-05\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.3413e-05\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2521e-05\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1649e-05\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.0793e-05\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.9955e-05\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9134e-05\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8331e-05\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7544e-05\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6773e-05\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6018e-05\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5278e-05\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4553e-05\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3843e-05\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3147e-05\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.2467e-05\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1800e-05\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1147e-05\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0507e-05\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9881e-05\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9267e-05\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8666e-05\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8078e-05\n",
            "Finished training the model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONjN9e34vPwC"
      },
      "source": [
        "## Test the Model\n",
        "\n",
        "Now that the model is trained, we can test it. If we give it the value `10`, we should get a value very close to `19`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnRch66BvNFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af83bf9-d662-44d7-fc52-742ed28cb716"
      },
      "source": [
        "print(model.predict([10.0]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[18.984539]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ67rKM9367n"
      },
      "source": [
        "## Save the Model\n",
        "\n",
        "To load the trained model into TensorFlow Serving we first need to save it in the [SavedModel](https://www.tensorflow.org/guide/saved_model) format.  This will create a protobuf file in a well-defined directory hierarchy, and will include a version number.  [TensorFlow Serving](https://www.tensorflow.org/tfx/serving/serving_config) allows us to select which version of a model, or \"servable\" we want to use when we make inference requests.  Each version will be exported to a different sub-directory under the given path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9c2eOEHpjGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d637c1e9-cde2-4c44-a915-0de8d3d90889"
      },
      "source": [
        "MODEL_DIR = tempfile.gettempdir()\n",
        "\n",
        "version = 1\n",
        "\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "\n",
        "if os.path.isdir(export_path):\n",
        "    print('\\nAlready saved a model, cleaning up\\n')\n",
        "    !rm -r {export_path}\n",
        "\n",
        "model.save(export_path, save_format=\"tf\")\n",
        "\n",
        "print('\\nexport_path = {}'.format(export_path))\n",
        "!ls -l {export_path}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/1/assets\n",
            "\n",
            "export_path = /tmp/1\n",
            "total 56\n",
            "drwxr-xr-x 2 root root  4096 Jul  1 23:49 assets\n",
            "-rw-r--r-- 1 root root  3862 Jul  1 23:49 keras_metadata.pb\n",
            "-rw-r--r-- 1 root root 41258 Jul  1 23:49 saved_model.pb\n",
            "drwxr-xr-x 2 root root  4096 Jul  1 23:49 variables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-ARQOR87Mt2"
      },
      "source": [
        "## Examine Your Saved Model\n",
        "\n",
        "We'll use the command line utility `saved_model_cli` to look at the `MetaGraphDefs` and `SignatureDefs` in our SavedModel. The signature definition is defined by the input and output tensors, and stored with the default serving key."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M0VJORSN2w9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d92877ef-0e6f-4954-c6f6-7c65a42758f8"
      },
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['dense_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: serving_default_dense_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0701 23:50:08.062781 139788172629888 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name=u'dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name=u'dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name=u'dense_input')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name=u'dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 1), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 1), dtype=tf.float32, name=u'dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS3dODJgAB87"
      },
      "source": [
        "## Run the TensorFlow Model Server\n",
        "\n",
        "We will now launch the TensorFlow model server with a bash script. We will use the argument `--bg` to run the script in the background.\n",
        "\n",
        "Our script will start running TensorFlow Serving and will load our model. Here are the parameters we will use:\n",
        "\n",
        "* `rest_api_port`: The port that you'll use for requests.\n",
        "\n",
        "\n",
        "* `model_name`: You'll use this in the URL of your requests.  It can be anything.\n",
        "\n",
        "\n",
        "* `model_base_path`: This is the path to the directory where you've saved your model.\n",
        "\n",
        "Also, because the variable that points to the directory containing the model is in Python, we need a way to tell the bash script where to find the model. To do this, we will write the value of the Python variable to an environment variable using the `os.environ` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhXu-01eOFGE"
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJDhHNJVnaLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "734a24c1-5e21-4d94-cb1b-b595dabccbad"
      },
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=helloworld \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWBzpit--6hS"
      },
      "source": [
        "Now we can take a look at the server log."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_PudlFqdtfl",
        "outputId": "4ab7d377-d18e-4432-e69f-41c06259fda1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-01 23:53:20.670573: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /tmp/1\n",
            "2021-07-01 23:53:20.672659: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 33309 microseconds.\n",
            "2021-07-01 23:53:20.672990: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /tmp/1/assets.extra/tf_serving_warmup_requests\n",
            "2021-07-01 23:53:20.673122: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: helloworld version: 1}\n",
            "2021-07-01 23:53:20.673743: I tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\n",
            "2021-07-01 23:53:20.673824: I tensorflow_serving/model_servers/server.cc:367] Profiler service is enabled\n",
            "2021-07-01 23:53:20.674318: I tensorflow_serving/model_servers/server.cc:393] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "2021-07-01 23:53:20.674880: I tensorflow_serving/model_servers/server.cc:414] Exporting HTTP/REST API at:localhost:8501 ...\n",
            "[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD_dr7baFJ-s"
      },
      "source": [
        "## Create JSON Object with Test Data\n",
        "\n",
        "We are now ready to construct a JSON object with some data so that we can make a couple of inferences. We will use $x=9$ and $x=10$ as our test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwxEEnOei38-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d1adb9c-4102-407b-e63f-829be0b7207f"
      },
      "source": [
        "xs = np.array([[9.0], [10.0]])\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": xs.tolist()})\n",
        "print(data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"signature_name\": \"serving_default\", \"instances\": [[9.0], [10.0]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ0KtEF7Fjer"
      },
      "source": [
        "## Make Inference Request\n",
        "\n",
        "Finally, we can make the inference request and get the inferences back. We'll send a predict request as a POST to our server's REST endpoint, and pass it our test data. We'll ask our server to give us the latest version of our model by not specifying a particular version. The response will be a JSON payload containing the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGvFyuIzW6n6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805e03ed-902a-4e30-9dae-0708573c8d7c"
      },
      "source": [
        "# if this cell fails execution because of an \"...Failed to establish a new connection...\" error,\n",
        "# try replacing in the link below 'localhost' with '127.0.0.1'\n",
        "\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8501/v1/models/helloworld:predict', data=data, headers=headers)\n",
        "\n",
        "print(json_response.text)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"predictions\": [[16.9867802], [18.984539]\n",
            "    ]\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DKLw7PwI928"
      },
      "source": [
        "We can also look at the predictions directly by loading the value for the `predictions` key."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-x87o_DqfOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "114bbfd9-5b05-4882-aec5-40f95c9415dc"
      },
      "source": [
        "predictions = json.loads(json_response.text)['predictions']\n",
        "print(predictions)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16.9867802], [18.984539]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiPct1c9kLoX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}