{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Splits_Slicing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMClZsKbzwaN0Cv6vZFfmIU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"snp4FVnyjoRi"},"source":["### Import libraries and set up the splits"]},{"cell_type":"code","metadata":{"id":"gOhw_MaCjjkl"},"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from os import getcwd\n","\n","print(tf.__version__)\n","print(tfds.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fEeWz0Kzju4x"},"source":["### Loab mobilenet model and its features"]},{"cell_type":"code","metadata":{"id":"Niv6fL7Mjydf"},"source":["import tensorflow_hub as hub \n","\n","model_selection = (\"mobilenet_v2\", 224, 1280) \n","handle_base, pixels, FV_SIZE = model_selection\n","IMAGE_SIZE = (pixels, pixels)\n","\n","filePath = f\"{getcwd()}/data\"\n","\n","# You can also use directly to download from the source.\n","\n","# MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n","# feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n","#                                    input_shape=IMAGE_SIZE + (3,))\n","\n","# The data is already downloaded for you at the filepath\n","\n","feature_extractor = hub.KerasLayer(filePath+'/mobilenet_v2_feature_vector',input_shape=IMAGE_SIZE + (3,))\n","feature_extractor.trainable = True  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uitw63zLj1jO"},"source":["### Split the dataset"]},{"cell_type":"code","metadata":{"id":"90qMQC3sj35Q"},"source":["# EXERCISE: Split the dataset\n","\n","splits = [\"train[:10%]\", \"train[-5%:]\", \"train[-10%:-5%]\"] #DESCRIBE YOUR SPLITS HERE#]\n","    \n","# Remember to use `cats_vs_dogs:4.*.*` \n","# https://www.tensorflow.org/datasets/catalog/cats_vs_dogs\n","    \n","# It has been downloaded for you so use the data_dir parameter \n","# else it will try to download the dataset and give you an error here\n","\n","splits, info = tfds.load(name='cats_vs_dogs:4.*.*', \n","                         data_dir=filePath, \n","                         split=splits,\n","                         with_info=True) #YOUR CODE HERE)\n","\n","(train_examples, validation_examples, test_examples) = splits\n","\n","# Testing lengths of the data if they are loaded correctly. Do not edit the code below\n","    \n","train_len = len(list(train_examples))\n","validation_len = len(list(validation_examples))\n","test_len = len(list(test_examples))\n","print(train_len)\n","print(validation_len)\n","print(test_len)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uVaG2eawmNUA"},"source":["### Shuffle and map the new batches"]},{"cell_type":"code","metadata":{"id":"5kJzOqs6mLwr"},"source":["num_examples = 500 # DO NOT CHANGE THIS FOR THE GRADER, UPDATE AND USE IT WHEN PLAYING AROUND AND TRAINING IT LOCALLY.\n","num_classes = 2\n","\n","\n","def format_image(features):\n","    image = features['image']\n","    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n","    return  image, features['label']\n","\n","BATCH_SIZE =  16 # DO NOT EDIT\n","\n","# For training batches, shuffle the examples by num_examples, map using the function defined above\n","# and batching using the batch_size.\n","\n","# For validation and test batches, just avoid shuffling and follow the rest as training batch example\n","\n","train_batches = train_examples.map(lambda features: format_image(features)).shuffle(num_examples).batch(BATCH_SIZE) #YOUR CODE HERE \n","validation_batches = validation_examples.map(lambda features: format_image(features)).batch(BATCH_SIZE) #YOUR CODE HERE \n","test_batches = test_examples.map(lambda features: format_image(features)).batch(BATCH_SIZE) #YOUR CODE HERE "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MAgXyayOn2Gg"},"source":["### Define your transfer learning model"]},{"cell_type":"code","metadata":{"id":"g2Ci-Hesn5Eo"},"source":["# EXERCISE: Define the model\n","\n","# The new model will take the features from the mobilenet via transfer learning\n","# And add a new dense layer at the bottom, with 2 classes -- for cats and dogs\n","\n","model = tf.keras.Sequential([\n","        feature_extractor,\n","        tf.keras.layers.Dense(2, activation=\"softmax\")\n","        #YOUR CODE HERE, # USE the feature extractor which you loaded before\n","        #YOUR CODE HERE # Define a keras dense layer with 2 classes and softmax activation\n","])\n","\n","# Model summary to test your model layers, output shape and number of parameters.\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z7_MmzJPpBPE"},"source":["### Training your model"]},{"cell_type":"code","metadata":{"id":"ddXCxmo_pAUz"},"source":["# # Compile the model with adam optimizer and sparse categorical crossentropy, \n","# # and track the accuracy metric\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n","\n","# # Train it for a number of epochs. You should not need many (max 5)\n","# # Train on the train_batches, and validation on the validation_batches \n","\n","EPOCHS = 5 # YOUR CODE HERE\n","\n","history = model.fit(train_batches, epochs=EPOCHS, validation_data=validation_batches,verbose=1)\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLDfTPCjpyyB"},"source":["# # Evaluate the model on the test batches\n","eval_results = model.evaluate(test_batches)\n","\n","# # And print the results. \n","for metric, value in zip(model.metrics_names, eval_results):\n","     print(metric + ': {:.4}'.format(value))"],"execution_count":null,"outputs":[]}]}